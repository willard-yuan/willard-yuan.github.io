<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="google-site-verification" content="aexITLS38FdIRzwj25OVWxm87rpa9l-UV0URTyC9cTs" />
  <title>
    技术翻译：OpenCV行人检测
    
  </title>
  <link rel="stylesheet" href="../css/site.css">
  <link href="//cdn.bootcss.com/font-awesome/4.4.0/css/font-awesome.css" rel="stylesheet">
  <link href="/favicon.ico" rel="shortcut icon" type="image/x-icon" />
  
  <link href="/blog/feed.xml" type="application/rss+xml" rel="alternate" title="Latest 10 blog posts (atom)" />

  

  

  
</head>

<body>
  <div class="header-container">
    <header class="inner">
      
      <nav>
        <a class="" href="/">About</a>
        <a class="" href="/project/">Project</a>
        <!--<a class="" href="/resume/">Resume</a>-->
	      <!--<a href="/yuanyong_resume_cn.pdf">Resume</a>-->
	      <a href="/YongYuan_resume.pdf">Resume</a>
        <!--<a class="" href="/publication/">Publication</a>-->
        <a class="" href="/blog/">Blog</a>
	      <a href="/books/">Book</a>
		    <a href="/timeline/">Times</a>
        <a href="https://github.com/willard-yuan">GitHub</a>
      </nav>
	  

      <div class="pull-right right logo">
        <!--<div class="name">
          <a href="/">Yong Yuan</a><br />
          <small>
            <em>
              
                <a href="/">developer</a>
              
            </em>
          </small>
        </div>-->
        <a href="http://yongyuan.name/"><img class="avatar" src="http://ose5hybez.bkt.clouddn.com/index/YongYuan.png" alt="My profile picture" /></a>
      </div>
      <div class="clear"></div>
    </header>
    <div class="clear"></div>
  </div>

  <link rel="stylesheet" href="../css/blog.css">



<div id="container">
<article>
<div class="inner">
<div class = "post-header">
  <h1>
    技术翻译：OpenCV行人检测
  </h1>
  <ul class="meta">
  	<i class="fa fa-calendar"></i>
  	2015年11月10日
  	<i class="space"></i>
  	<i class="fa fa-archive"></i>
  	<a class="tag" href="http://localhost:4000/blog/categories.html#计算机视觉">计算机视觉</a>
  	<i class="space"></i>
  	<i class="fa fa-tags"></i>
  	
  	    <a class="tag" href="http://localhost:4000/tag/#OpenCV">OpenCV</a>
  	    <i class="space"></i>
  	
  	<i class="space"></i> 字数:10429
  </ul>
</div>
</div>

  <div class="post">
        <div id="content">
          <div class ="sidebox">
              <div class ="sidebar">
              <div class="toc"></div>
              </div>
          </div>
  	   <blockquote>
  <p>本文翻译自：<a href="https://www.pyimagesearch.com/2015/11/09/pedestrian-detection-opencv/">Pedestrian Detection OpenCV</a>。</p>
</blockquote>

<p>你知道OpenCV里面已经内置的行人检测方法吗？在OpenCV里面，有一个预先训练好了的HOG+线性SVM模型，能够对图像和视频中的行人进行检测。如果你还不熟悉方向梯度直方图HOG和线性SVM方法，我建议你阅读<a href="http://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/">方向梯度直方图和物体检测</a>这篇文章，在这篇文章中，我对该框架分了6步进行讨论。</p>

<p>如果你已经熟悉了这个过程，或者你仅仅只是想看看OpenCV行人检测的代码，那么现在就打开一个新文件，并将它命名为<code class="highlighter-rouge">detect.py</code>，开始我们的编程之旅吧：</p>

<div class="preserve-original-format">

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17</pre></td><td class="code"><pre><span class="c"># import the necessary packages</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">imutils.object_detection</span> <span class="kn">import</span> <span class="n">non_max_suppression</span>
<span class="kn">from</span> <span class="nn">imutils</span> <span class="kn">import</span> <span class="n">paths</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">imutils</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c"># construct the argument parse and parse the arguments</span>
<span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-i"</span><span class="p">,</span> <span class="s">"--images"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"path to images directory"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="c"># initialize the HOG descriptor/person detector</span>
<span class="n">hog</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HOGDescriptor</span><span class="p">()</span>
<span class="n">hog</span><span class="o">.</span><span class="n">setSVMDetector</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">HOGDescriptor_getDefaultPeopleDetector</span><span class="p">())</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

</div>

<p><strong>第2-8行</strong>导入一些我们必要的包，我们导入<code class="highlighter-rouge">print_function</code>确保我们的代码同时在Python2.7和Python3上兼容，这样可以使得我们的代码能够在OpenCV2.4.X和OPenCV3上都能够工作，然后，从我的<a href="https://github.com/jrosebr1/imutils">imutils</a>包中我们导入<code class="highlighter-rouge">non_max_suppression</code>函数。</p>

<p>如果你还没有安装<code class="highlighter-rouge">imutils</code>，可以通过<code class="highlighter-rouge">pip</code>来安装：</p>

<div class="language-sh highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>pip install imutils
</code></pre>
</div>

<p>如果你已经安装了<code class="highlighter-rouge">imutils</code>，你需要把它更新到最新版(v0.3.1)，在这个版本里面，包含了<code class="highlighter-rouge">non_max_suppression</code>函数的实现，以及其它一些微小的更新：</p>

<div class="language-sh highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>pip install --upgrade imutils
</code></pre>
</div>

<p>我已经在我的PyImageSearch博客上在两次讲到过非极大抑制(non-maxima suppression)方法，一次是在<a href="http://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/">Python非极大抑制用于物体检测</a>，一篇是在<a href="http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/">用Python实现更快的非极大抑制</a>，无论是哪一种情形，非极大抑制的宗旨都是获取多个重叠的边框(bounding box)，并且将他们减少至仅有一个边框。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_032.jpg" alt="drawing" /></p>
<center>图1：左图有很多检测错误的边框；右图采用非极大抑制后，使得我们可以抑制那些重叠的区域，将正确的边框留下来</center>

<p>非极大抑制方法可以减少在进行行人检测过程中的假阳率。</p>

<p><strong>第11-13行</strong>处理我们命令行传入的参数，这里，我们只需要一个切换<code class="highlighter-rouge">--images</code>，用它来传入待检测行人的图像目录。</p>

<p>最后，<strong>第16行和17行</strong>初始化我们的行人检测器。首先，我们调用<code class="highlighter-rouge">hog = cv2.HOGDescriptor()</code>来初始化方向梯度直方图描述子，然后，我们调用<code class="highlighter-rouge">setSVMDetector</code>来设置支持向量机(Support Vector Machine)使得它成为一个预先训练好了的行人检测器。</p>

<p>到了这里，我们的OpenCV行人检测器已经完全载入了，我们只需要把它应用到一些图像上：</p>

<div class="preserve-original-format">

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre></td><td class="code"><pre><span class="c"># import the necessary packages</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">imutils.object_detection</span> <span class="kn">import</span> <span class="n">non_max_suppression</span>
<span class="kn">from</span> <span class="nn">imutils</span> <span class="kn">import</span> <span class="n">paths</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">imutils</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c"># construct the argument parse and parse the arguments</span>
<span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-i"</span><span class="p">,</span> <span class="s">"--images"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"path to images directory"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="c"># initialize the HOG descriptor/person detector</span>
<span class="n">hog</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">HOGDescriptor</span><span class="p">()</span>
<span class="n">hog</span><span class="o">.</span><span class="n">setSVMDetector</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">HOGDescriptor_getDefaultPeopleDetector</span><span class="p">())</span>

<span class="c"># loop over the image paths</span>
<span class="k">for</span> <span class="n">imagePath</span> <span class="ow">in</span> <span class="n">paths</span><span class="o">.</span><span class="n">list_images</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s">"images"</span><span class="p">]):</span>
	<span class="c"># load the image and resize it to (1) reduce detection time</span>
	<span class="c"># and (2) improve detection accuracy</span>
	<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">imagePath</span><span class="p">)</span>
	<span class="n">image</span> <span class="o">=</span> <span class="n">imutils</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
	<span class="n">orig</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

	<span class="c"># detect people in the image</span>
	<span class="p">(</span><span class="n">rects</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">=</span> <span class="n">hog</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">winStride</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
		<span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>

	<span class="c"># draw the original bounding boxes</span>
	<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">rects</span><span class="p">:</span>
		<span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

	<span class="c"># apply non-maxima suppression to the bounding boxes using a</span>
	<span class="c"># fairly large overlap threshold to try to maintain overlapping</span>
	<span class="c"># boxes that are still people</span>
	<span class="n">rects</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">]</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">rects</span><span class="p">])</span>
	<span class="n">pick</span> <span class="o">=</span> <span class="n">non_max_suppression</span><span class="p">(</span><span class="n">rects</span><span class="p">,</span> <span class="n">probs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">overlapThresh</span><span class="o">=</span><span class="mf">0.65</span><span class="p">)</span>

	<span class="c"># draw the final bounding boxes</span>
	<span class="k">for</span> <span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">yA</span><span class="p">,</span> <span class="n">xB</span><span class="p">,</span> <span class="n">yB</span><span class="p">)</span> <span class="ow">in</span> <span class="n">pick</span><span class="p">:</span>
		<span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">yA</span><span class="p">),</span> <span class="p">(</span><span class="n">xB</span><span class="p">,</span> <span class="n">yB</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

	<span class="c"># show some information on the number of bounding boxes</span>
	<span class="n">filename</span> <span class="o">=</span> <span class="n">imagePath</span><span class="p">[</span><span class="n">imagePath</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s">"/"</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
	<span class="k">print</span><span class="p">(</span><span class="s">"[INFO] {}: {} original boxes, {} after suppression"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
		<span class="n">filename</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rects</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">pick</span><span class="p">)))</span>

	<span class="c"># show the output images</span>
	<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"Before NMS"</span><span class="p">,</span> <span class="n">orig</span><span class="p">)</span>
	<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"After NMS"</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
	<span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

</div>

<p>在<strong>第20行</strong>我们对我们的<code class="highlighter-rouge">--images</code>目录下的图像进行循环，这篇博文中使用的例子样本是从<a href="http://pascal.inrialpes.fr/data/human/">INRIA Person Dataset</a>这个很流行的人物库上抽取的，更具体的说，是从GRAZ-01子集中抽取出来的，这些图片存放在源码目录下面了。</p>

<p><strong>第23-25行</strong>载入磁盘中的图像，并且将图像裁剪到最大宽度为400个像素，之所以降低我们的图像维度(其实就是之所以对我们的图像尺寸进行裁剪)主要有两个原因：</p>

<ol>
  <li>减小图像的尺寸可以减少在<a href="http://www.pyimagesearch.com/2015/03/16/image-pyramids-with-python-and-opencv/">图像金字塔</a>中<a href="http://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/">滑窗</a>的数目，如此可以降低检测的时间，从而提高整体检测的吞吐量。</li>
  <li>调整图像的尺寸能够整体提高行人检测的精度，也就是假阳率。</li>
</ol>

<p>真正对图像中的行人进行检测的代码是在<strong>第28行和29行</strong>，通过调用<code class="highlighter-rouge">detectMultiScale</code>的<code class="highlighter-rouge">hog</code>描述子方法。这个<code class="highlighter-rouge">detectMultiScale</code>方法构造了一个尺度<code class="highlighter-rouge">scale=1.05</code>的图像金字塔，以及一个分别在x方向和y方向步长为(4,4)像素大小的滑窗。</p>

<p>窗口的大小固定在32*128像素大小，这个设置是按照 seminal Dalal和Triggs论文<a href="Histograms of Oriented Gradients for Human Detection"></a>来设置的。<code class="highlighter-rouge">detectMultiScale</code>函数会返回一个2-元组的<code class="highlighter-rouge">rects</code>，或者是图像中每一个行人的边框坐标(x,y)，以及由SVM在每一次检测中返回的<code class="highlighter-rouge">weights</code>置信值(我们一般也成为分数，译者注)。</p>

<p><code class="highlighter-rouge">scale</code>的尺度设置得越大，在图像金字塔中层的数目就越少，相应的检测速度就越快，但是尺度太大会导致行人出现漏检；同样的，如果<code class="highlighter-rouge">scale</code>设置得太小，将会急剧的增加图像金字塔的层数，这样不仅耗费计算资源，而且还会急剧地增加检测过程中出现的假阳数目(也就是不是行人的被检测成行人)。这表明，<code class="highlighter-rouge">scale</code>是在行人检测过程中它是一个重要的参数，需要对<code class="highlighter-rouge">scale</code>进行调参。我会在后面的文章中对<code class="highlighter-rouge">detectMultiScale</code>中的每个参数做些调研。</p>

<p><strong>第32行和33行</strong>获取我们的初始边框，并将它们在图像上框出来。</p>

<p>不过，你将会看到在一些图像上有的行人框出来的框，有很多重叠的边框，如上面1图所示。</p>

<p>针对这种情况，我们有两种选择。一种选择是检测一个边框是否完全包含了另一个边框(你可以看看<a href="https://github.com/Itseez/opencv/blob/master/samples/python2/peopledetect.py">OpenV中的一些实现例子</a>)。另外一种选择是应用非极大抑制方法，通过设置一个阈值来抑制那些重叠的边框，这就是第38行和39行所干的事。</p>

<p><strong><em>注意</em></strong>：如果你想了解更多HOG框架和非极大抑制，我推荐你阅读<a href="http://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/">方向梯度直方图和物体检测</a>。在那篇博文中，你可以查看<a href="http://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/">Python非极大抑制用于物体检测</a>，以及后面更新的<a href="http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/">Malisiewicz方法</a>。</p>

<p>在应用非极大抑制后，我们在第42行和43行画出最终的边框，在<strong>第46-48行</strong>中我们展示图像的一些基本信息，以及检测到的边框数目，在<strong>第51-53行</strong>，在屏幕最终显示我们输入的图像。</p>

<h2 id="行人检测结果">行人检测结果</h2>

<p>为了看看我们写的行人检测脚本的实际效果，我们只需要执行下面命令：</p>

<div class="language-sh highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>python detect.py --images images
</code></pre>
</div>

<p>下图是一张行人检测的结果图：</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_258.jpg" alt="drawing" /></p>
<center>图2：检测效果</center>

<p>上图我们检测到了站在警车旁的单个行人。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_014.jpg" alt="drawing" /></p>
<center>图3：在前景和背景中分别检测到了1个人</center>

<p>上面我们可以看到在前景中的男人被检测到了，同时背景中推着婴儿车的女人也检测到了。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_032.jpg" alt="drawing" /></p>
<center>图4：一个展示为什么用非极大抑制很重要的例子</center>

<p>图4的例子展示了为什么用非极大抑制很重要。<code class="highlighter-rouge">detectMultiScale</code>函数除了将正确的边框检测出来外，还把两个边框边框检测出来了，这两个错误的边框将图像中的行人覆盖了。通过使用非极大抑制，我们可以抑制错误的边框，只留下正确检测的边框。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_029.jpg" alt="drawing" /></p>
<center>图5：另一个展示非极大抑制效果的例子</center>

<p>我们再一次可以看到，有很多错误的边框被检测出来了，通过使用非极大抑制，我们可以抑制错误的边框，只留下正确检测的边框。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_156.jpg" alt="drawing" /></p>
<center>图6：在一个购物中心检测行人</center>

<p>图6在一个购物中心进行行人检测，图中，有两个人正向摄像头走进，另外一个人正远离摄像头，不管是哪种情形，我们的HOG检测方法都能够准确的检测出行人。在<code class="highlighter-rouge">non_maxima_suppression </code>函数中较大的<code class="highlighter-rouge">overlapThresh</code>能够确保那些部分重叠了的边框不会被抑制。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_390.jpg" alt="drawing" /></p>
<center>图7：在模糊图片中检测行人</center>

<p>老实说，我对上面图片的检测结果有点儿惊讶，因为一般而言HOG描述子在运动模糊的图片上检测效果不是很好，不过在这幅图像上，我们却将行人检测出来了。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_293.jpg" alt="drawing" /></p>
<center>图8：在室外街道上检测行人</center>

<p>这里有另外一个多个重叠边框的例子，不过因为我们的<code class="highlighter-rouge">overlapThresh</code>设置得比较大，所以这些边框没有被抑制，从而能够将正确的检测结果留下来。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_265.jpg" alt="drawing" /></p>
<center>图9：检测一张具有4个成员的家庭的图片</center>

<p>图9的例子展示了HOG+SVM行人检测器的多功能性，我们不仅能够检测到成年的男人，也能够检测到那三个小孩(注意：该检测器不能检测到躲藏在他老爸后面的小孩)。</p>

<p><img src="https://www.pyimagesearch.com/wp-content/uploads/2015/11/pedestrian_detection_person_454.jpg" alt="drawing" /></p>
<center>图10：对路标标识进行行人检测</center>

<p>我将图10放在最后是因为我发觉这非常的有趣，我们可以很清楚的看到这只是一个路标标识，标识表示人行横道，然而，HOG+SVM检测器将它们在图中框出来了，实际上它们却并不是行人。</p>

<h2 id="总结">总结</h2>

<p>在这篇博文中，我们已经学到了怎样使用OpenCV的库以及Python来进行行人检测。</p>

<p>实际上OpenCV库已经内置了一个预先训练好了的<a href="http://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/">HOG+线性SVM检测器</a>的模型，它是基于Dalal和Triggs论文里的方法来自动的实现图像中行人的检测。</p>

<p>虽然HOG的方法比Haar counter-part的精度要高，不过它仍需要对<code class="highlighter-rouge">detectMultiScale</code>进行合理的设置。在后面的博文中，我会对<code class="highlighter-rouge">detectMultiScale</code>中的每一个参数做一个调研，已经怎样调参的细节，并陈述在精度和性能之间的折中。</p>

<p>不管怎么说，我都希望你喜欢这篇博文！我正打算在后面给出更多的关于物体检测的教程，如果你希望这些教程出来后能够获得及时的通知，你可以考虑订阅我的博客。</p>

<p>我已经在<strong>PyImageSearch Gurus course</strong>里面包含了HOG+线性SVM的物体检测方法，你可以看看。</p>

  	</div>
	</div>

<div class="content-play">
    <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">请我喝杯咖啡</a></p>
    <div class="hide_box-play"></div>
    <div class="shang_box-play">
        <a class="shang_close-play" href="javascript:void(0)" onclick="dashangToggle()" title="关闭"><img src="/images/payimg/close.jpg" alt="取消" /></a>
        <div class="shang_tit-play">
            <p>感谢您的支持，我会继续写出更优秀的文章!</p>
        </div>
        <div class="shang_payimg">
            <img src="/images/payimg/weipayimg.jpg" alt="扫码支持" title="扫一扫" />
        </div>
        <div class="shang_payimg">
            <img src="/images/payimg/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
        </div>
        <div class="pay_explain">请我喝杯咖啡</div>
        <div class="shang_payselect">
            <div class="pay_item" data-id="weipay">
                <span class="pay_logo"><img src="/images/payimg/wechat.jpg" alt="微信" /></span>
            </div>
            <div class="pay_item checked" data-id="alipay">
                <span class="pay_logo"><img src="/images/payimg/alipay.jpg" alt="支付宝" /></span>
            </div>
        </div>
        <div class="shang_info-play">
            <p>打开<span id="shang_pay_txt">微信</span>扫一扫，即可进行扫码打赏哦</p>
        </div>
    </div>
</div>
<script type="text/javascript">
    function dashangToggle(){
        $(".hide_box-play").fadeToggle();
        $(".shang_box-play").fadeToggle();
    }
</script>

<div style="text-align:center;margin:50px 0; font:normal 14px/24px 'MicroSoft YaHei';"></div>

<style type="text/css">
  .content-play{}
  .hide_box-play{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
  .shang_box-play{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
  .shang_box-play img{border:none;border-width:0;}
  .dashang{display:block;width:140px;margin:5px auto;height:40px;line-height:25px;padding:8px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
  .dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
  .shang_close-play{float:right;display:inline-block;
    margin-right: 10px;margin-top: 20px;
  }
  .shang_logo{display:block;text-align:center;margin:20px auto;}
  .shang_tit-play{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;background: url('/images/payimg/cy-reward-title-bg.jpg');font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
  .shang_tit-play p{color:#a3a3a3;text-align:center;font-size:16px;}
  .shang_payimg{width:140px;padding:10px;/*padding-left: 80px; border:6px solid #EA5F00;**/margin:0 auto;border-radius:3px;height:140px;display:inline-block;}
  .shang_payimg img{display:inline-block;margin-right:10px;float:left;text-align:center;width:140px;height:140px; }
  .pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
  .shang_payselect{text-align:center;margin:0 auto;margin-top:40px;cursor:pointer;height:60px;width:500px;margin-left:110px;}
  .shang_payselect .pay_item{display:inline-block;margin-right:140px;float:left;}
  .shang_info-play{clear:both;}
  .shang_info-play p,.shang_info-play a{color:#C3C3C3;text-align:center;font-size:12px;text-decoration:none;line-height:2em;}
</style>


</article>

<!--翻页功能-->
<section class="inner">
<ul class="pager">
    
    <li class="previous">
       <a href="/blog/picsearch-is-now-an-open-source-project.html">←图像检索：PicSearch is now an open source project</a>
    </li>
    
    
    <li class="next">
    	<a href="/blog/deep-face-recognition-note.html">人脸识别：Deep Face Recognition论文阅读→</a>
    </li>
    
 </ul>
</section>

<!--评论功能-->
<section class="comments inner duoshuo">
<!-- Disqus Comment BEGIN -->
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'yongyuan'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
<!-- Disqus Comment END -->

</section>
</div>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    <!--displayMath: [['$$','$$'], ['\[','\]']],-->
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>



  <!--<div class="separator"></div>-->

  <footer>
    <div  style="border-bottom: 1px solid #eee"></div>
    <p class="linkings">
    Friend: <a href="https://sites.google.com/site/raphaelitemou/">Lichao</a>&nbsp&nbsp&nbsp&nbsp<a href="http://cmp.felk.cvut.cz/~toliageo/publi.html">Tolias</a>&nbsp&nbsp&nbsp&nbsp<a href="http://www.heyuhang.com/">heyuhang</a>&nbsp&nbsp&nbsp&nbsp<a href="https://blog.yuanbin.me/">yuanbin</a>&nbsp&nbsp&nbsp&nbsp<a href="http://freemind.pluskid.org/">pluskid</a>
    </p>
    <!--p class="linkings">
        Utils: <a href="http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html">rogerioferis</a>&nbsp&nbsp&nbsp&nbsp<a href="http://caffe.berkeleyvision.org/">Caffe</a>&nbsp&nbsp&nbsp&nbsp<a href="http://scikit-learn.org/stable/index.html">scikit-learn</a>&nbsp&nbsp&nbsp&nbsp<a href="http://www.astroml.org/index.html">AstroML</a></a>&nbsp&nbsp&nbsp&nbsp<a href="http://scikit-image.org/">scikit-image</a></a>&nbsp&nbsp&nbsp&nbsp<a href="http://gitxiv.com/">GitXiv</a>
    </p-->
    <p>
      Made with <a href="http://jekyllrb.com/">Jekyll</a>,
      hosted on <a href="https://github.com/willard-yuan/willard-yuan.github.io">Github Pages</a>. Inspired by <a href="http://sebastien.saunier.me/">saunier</a>, designed by <a href="http://yongyuan.name">Willard</a>.
    </p>
    <p>
      <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Attribution-NonCommercial-ShareAlike 4.0 International</a> 2013-2018
    </p>
    <!--ul class="links">
      <li>
        <a href="https://github.com/willard-yuan" title="See my code on GitHub">
          <i class="icon-github"></i>
        </a>
      </li>
      <li>
        <a href="https://twitter.com/intent/follow?screen_name=yongyuan001" title="Follow me on Twitter">
          <i class="icon-twitter"></i>
        </a>
      </li>
      <li>
        <a href="https://www.linkedin.com/in/sebastiensaunier" title="Connect with me on LinkedIn">
          <i class="icon-linkedin"></i>
        </a>
      </li>
      <li>
        <a href="https://plus.google.com/+SebastienSaunier?rel=author" title="I need this link for authorship reasons">
          <i class="icon-google-plus"></i>
        </a>
      </li>
      <li>
        <a href="https://pinboard.in/u:ssaunier" title="Browse my bookmarks about Programming">
          <i class="icon-bookmarks"></i>
        </a>
      </li>
      <li>
        <a href="/feed.xml" title="Subscribe to my blog with RSS">
          <i class="icon-feed"></i>
        </a>
      </li>
    </ul-->
  </footer>

<script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>

</body>
</html>
