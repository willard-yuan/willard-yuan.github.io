<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="google-site-verification" content="aexITLS38FdIRzwj25OVWxm87rpa9l-UV0URTyC9cTs" />
  <title>
    图像检索：BoW图像检索原理与实战
    
  </title>
  <link rel="stylesheet" href="../css/site.css">
  <link href="//cdn.bootcss.com/font-awesome/4.4.0/css/font-awesome.css" rel="stylesheet">
  <link href="/favicon.ico" rel="shortcut icon" type="image/x-icon" />
  
  <link rel="alternate" type="application/atom+xml" title="RSS Feed for Yong Yuan's blog" href="/feed.xml" />

  

  

  
</head>

<body>
  <div class="header-container">
    <header class="inner">
      
      <nav>
        <a class="" href="/">About</a>
        <a class="" href="/project/">Project</a>
        <!--<a class="" href="/resume/">Resume</a>-->
	      <!--<a href="/yuanyong_resume_cn.pdf">Resume</a>-->
	      <a href="/resume/">Resume</a>
        <!--<a class="" href="/publication/">Publication</a>-->
        <a class="" href="/blog/">Blog</a>
	      <a href="/books/">Book</a>
		    <a href="/timeline/">Times</a>
        <a href="https://github.com/willard-yuan">Github</a>
      </nav>
	  

      <div class="pull-right right logo">
        <!--<div class="name">
          <a href="/">Yong Yuan</a><br />
          <small>
            <em>
              
                <a href="/">developer</a>
              
            </em>
          </small>
        </div>-->
        <a href="http://yongyuan.name/"><img class="avatar" src="/images/YongYuan.png" alt="My profile picture" /></a>
      </div>
      <div class="clear"></div>
    </header>
    <div class="clear"></div>
  </div>

  <link rel="stylesheet" href="../css/blog.css">



<div id="container">
<article>
<div class="inner">
<div class = "post-header">
  <h1>
    图像检索：BoW图像检索原理与实战
  </h1>
  <ul class="meta">
  	<i class="fa fa-calendar"></i>
  	2015年08月13日
  	<i class="space"></i>
  	<i class="fa fa-archive"></i>
  	<a class="tag" href="/blog/categories.html#Image Retrieval">Image Retrieval</a>
  	<i class="space"></i>
  	<i class="fa fa-tags"></i>
  	
  	    <a class="tag" href="/tag/#CBIR">CBIR</a>
  	    <i class="space"></i>
  	
  	<i class="space"></i> 字数:14675
  </ul>
</div>
</div>

  <div class="post">
        <div id="content">
          <div class ="sidebox">
              <div class ="sidebar">
              <div class="toc"></div>
              </div>
          </div>
  	   <p>这篇博文主要从原理和具体实战两个部分对词袋模型进行展开，实战部分包括Python实现和C++实现。</p>

<h2 id="bow">BoW词袋模型原理</h2>

<h3 id="section">模型简介</h3>

<p>BoW(Bag of Words)词袋模型最初被用在文本分类中，将文档表示成特征矢量。它的基本思想是假定对于一个文本，忽略其词序和语法、句法，仅仅将其看做是一些词汇的集合，而文本中的每个词汇都是独立的。简单说就是讲每篇文档都看成一个袋子（因为里面装的都是词汇，所以称为词袋，Bag of words即因此而来），然后看这个袋子里装的都是些什么词汇，将其分类。如果文档中猪、马、牛、羊、山谷、土地、拖拉机这样的词汇多些，而银行、大厦、汽车、公园这样的词汇少些，我们就倾向于判断它是一篇描绘乡村的文档，而不是描述城镇的。举个例子，有如下两个文档：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>文档一：Bob likes to play basketball, Jim likes too.    
文档二：Bob also likes to play football games.  
</code></pre>
</div>

<p>基于这两个文本文档，构造一个词典：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Dictionary = {1:”Bob”, 2. “like”, 3. “to”, 4. “play”, 5. “basketball”, 6. “also”, 7. “football”，8. “games”, 9. “Jim”, 10. “too”}
</code></pre>
</div>

<p>这个词典一共包含10个不同的单词，利用词典的索引号，上面两个文档每一个都可以用一个10维向量表示（用整数数字0~n（n为正整数）表示某个单词在文档中出现的次数）：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>文档一：[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]  
文档二：[1, 1, 1, 1 ,0, 1, 1, 1, 0, 0]  
</code></pre>
</div>

<p>向量中每个元素表示词典中相关元素在文档中出现的次数(下文中，将用单词的直方图表示)。不过，在构造文档向量的过程中可以看到，我们并没有表达单词在原来句子中出现的次序（这是词袋模型的缺点之一，不过瑕不掩瑜甚至在此处无关紧要）。</p>

<h3 id="bow-1">为什么要用BoW模型描述图像</h3>

<p>SIFT特征虽然也能描述一幅图像，但是每个SIFT矢量都是128维的，而且一幅图像通常都包含成百上千个SIFT矢量，在进行相似度计算时，这个计算量是非常大的，通行的做法是用聚类算法对这些矢量数据进行聚类，然后用聚类中的一个簇代表BoW中的一个视觉词，将同一幅图像的SIFT矢量映射到视觉词序列生成码本，这样每一幅图像只用一个码本矢量来描述，这样计算相似度时效率就大大提高了。</p>

<h3 id="bow-2">构建BoW码本步骤</h3>

<ol>
  <li>假设训练集有M幅图像，对训练图象集进行预处理。包括图像增强，分割，图像统一格式，统一规格等等。</li>
  <li>提取SIFT特征。对每一幅图像提取SIFT特征（每一幅图像提取多少个SIFT特征不定）。每一个SIFT特征用一个128维的描述子矢量表示，假设M幅图像共提取出N个SIFT特征。</li>
  <li>用K-means对2中提取的N个SIFT特征进行聚类，K-Means算法是一种基于样本间相似性度量的间接聚类方法，此算法以K为参数，把N个对象分为K个簇，以使簇内具有较高的相似度，而簇间相似度较低。聚类中心有k个（在BOW模型中聚类中心我们称它们为视觉词），码本的长度也就为k，计算每一幅图像的每一个SIFT特征到这k个视觉词的距离，并将其映射到距离最近的视觉词中（即将该视觉词的对应词频+1）。完成这一步后，每一幅图像就变成了一个与视觉词序列相对应的词频矢量。</li>
  <li>构造码本。码本矢量归一化因为每一幅图像的SIFT特征个数不定，所以需要归一化。测试图像也需经过预处理，提取SIFT特征，将这些特征映射到为码本矢量，码本矢量归一化，最后计算其与训练码本的距离，对应最近距离的训练图像认为与测试图像匹配。设视觉词序列为{眼睛 鼻子 嘴}（k=3），则训练集中的图像变为：</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>第一幅图像：[1 0 0]   
第二幅图像：[5 3 4]  
......
</code></pre>
</div>

<p>当然，在提取sift特征的时候，可以将图像打成很多小的patch，然后对每个patch提取SIFT特征。</p>

<p>总结一下，整个过程其实就做了三件事，首先提取对n幅图像分别提取SIFT特征，然后对提取的整个SIFT特征进行KMeans聚类得到k个聚类中心作为视觉单词表（或者说是词典），最后对每幅图像以单词表为规范对该幅图像的每一个SIFT特征点计算它与单词表中每个单词的距离，最近的+1，便可得到该幅图像的码本。实际上第三步是一个统计的过程，所以BoW中向量元素都是非负的。Yunchao Gong 2012年NIPS上有一篇用二进制编码用于图像快速检索的文章就是针对这类元素是非负的特征而设计的编码方案。</p>

<p>举两个例子来说明BoW词袋模型。第一个例子在介绍BoW词袋模型时一般资料里会经常使用到，就是将图像类比成文档，即一幅图像类比成一个文档，将图像中提取的诸如SIFT特征点类比成文档中的单词，然后把从图像库中所有提取的所有SIFT特征点弄在一块进行聚类，从中得到具有代表性的聚类中心(单词)，再对每一幅图像中的SIFT特征点找距离它最近的聚类中心(单词)，做词频(TF)统计，图解如下：</p>

<p><img src="/images/posts/2015-06-16/clustering.png" alt="clustering" /></p>

<p>做完词频(TF)统计后，为了降低停用词带来的干扰，可以再算个逆文档词频(IDF)，也就是给TF乘上个权重，该过程可以图解如下：</p>

<p><img src="/images/posts/2015-06-16/tfidf.png" alt="clustering" /></p>

<p>上面单词权重即逆文档词频(IDF)，那时通过统计每个单词包含了多少个文档然后按设定的一个对数权重公式计算得来的，具体如下：</p>

<p><img src="/images/posts/2015-06-16/idf.png" alt="clustering" /></p>

<p>对于上传上来的查询图像，提取SIFT然后统计tf后乘上上面的idf便可得到id-idf向量，然后进行L2归一化，用内积做相似性度量。</p>

<p>在做TF统计的时候，我们知道一般为了取得更好的效果，通常单词数目会做得比较大，动则上万或几十万，所以在做聚类的时候，可以对这些类中心做一个K-D树，这样在做TF词频统计的时候便可以加快单词直方图计算的速度。</p>

<p>上面举的例子对于初次接触BoW的人来说可能讲得不是那么的直观，小白菜可以举一个更直观的例子(虽然有些地方可能会不怎么贴切，但还是触及BoW的本质)，比如美国总统全国大选，假设有10000个比较有影响力的人参加总统竞选，这10000个人表示的就是聚类中心，他们最具有代表性(K-means做的就是得到那些设定数目的最具有代表性的特征点)，每个州类比成一幅图像，州里的人手里持的票就好比是SIFT特征点，这样的话，我们就可以对每个州做一个10000维的票数统计结果，这个统计出来的就是上面第一个例子里所说的词频向量。另外，我们还可以统计每个竞选人有多少个州投了他的票，那么就可以得到一个10000维长的对州的统计结果，这个结果再稍微和对数做下处理，便得到了所谓的逆文档词频。</p>

<h2 id="bowpython">BoW词袋模型图像检索Python实战</h2>

<p>上面的两个例子应该讲清楚了BoW词袋模型吧，下面就来看看BoW词袋模型用Python是怎么实现的。</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">#!/usr/local/bin/python2.7</span>
<span class="c">#python findFeatures.py -t dataset/train/</span>

<span class="kn">import</span> <span class="nn">argparse</span> <span class="kn">as</span> <span class="nn">ap</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.vq</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">rootsift</span> <span class="kn">import</span> <span class="n">RootSIFT</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c"># Get the path of the training set</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">ap</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-t"</span><span class="p">,</span> <span class="s">"--trainingSet"</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"Path to Training Set"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="s">"True"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="c"># Get the training classes names and store them in a list</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">"trainingSet"</span><span class="p">]</span>
<span class="c">#train_path = "dataset/train/"</span>

<span class="n">training_names</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>

<span class="n">numWords</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c"># Get all the path to the images and save them in a list</span>
<span class="c"># image_paths and the corresponding label in image_paths</span>
<span class="n">image_paths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">training_name</span> <span class="ow">in</span> <span class="n">training_names</span><span class="p">:</span>
    <span class="n">image_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">training_name</span><span class="p">)</span>
    <span class="n">image_paths</span> <span class="o">+=</span> <span class="p">[</span><span class="n">image_path</span><span class="p">]</span>

<span class="c"># Create feature extraction and keypoint detector objects</span>
<span class="n">fea_det</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FeatureDetector_create</span><span class="p">(</span><span class="s">"SIFT"</span><span class="p">)</span>
<span class="n">des_ext</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DescriptorExtractor_create</span><span class="p">(</span><span class="s">"SIFT"</span><span class="p">)</span>

<span class="c"># List where all the descriptors are stored</span>
<span class="n">des_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">image_paths</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">"Extract SIFT of </span><span class="si">%</span><span class="s">s image, </span><span class="si">%</span><span class="s">d of </span><span class="si">%</span><span class="s">d images"</span> <span class="o">%</span><span class="p">(</span><span class="n">training_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_paths</span><span class="p">))</span>
    <span class="n">kpts</span> <span class="o">=</span> <span class="n">fea_det</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">kpts</span><span class="p">,</span> <span class="n">des</span> <span class="o">=</span> <span class="n">des_ext</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">kpts</span><span class="p">)</span>
    <span class="c"># rootsift</span>
    <span class="c">#rs = RootSIFT()</span>
    <span class="c">#des = rs.compute(kpts, des)</span>
    <span class="n">des_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">image_path</span><span class="p">,</span> <span class="n">des</span><span class="p">))</span>

<span class="c"># Stack all the descriptors vertically in a numpy array</span>
<span class="c">#downsampling = 1</span>
<span class="c">#descriptors = des_list[0][1][::downsampling,:]</span>
<span class="c">#for image_path, descriptor in des_list[1:]:</span>
<span class="c">#    descriptors = np.vstack((descriptors, descriptor[::downsampling,:]))</span>

<span class="c"># Stack all the descriptors vertically in a numpy array</span>
<span class="n">descriptors</span> <span class="o">=</span> <span class="n">des_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">image_path</span><span class="p">,</span> <span class="n">descriptor</span> <span class="ow">in</span> <span class="n">des_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
    <span class="n">descriptors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">descriptors</span><span class="p">,</span> <span class="n">descriptor</span><span class="p">))</span>

<span class="c"># Perform k-means clustering</span>
<span class="k">print</span> <span class="s">"Start k-means: </span><span class="si">%</span><span class="s">d words, </span><span class="si">%</span><span class="s">d key points"</span> <span class="o">%</span><span class="p">(</span><span class="n">numWords</span><span class="p">,</span> <span class="n">descriptors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">voc</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">(</span><span class="n">descriptors</span><span class="p">,</span> <span class="n">numWords</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c"># Calculate the histogram of features</span>
<span class="n">im_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">image_paths</span><span class="p">),</span> <span class="n">numWords</span><span class="p">),</span> <span class="s">"float32"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_paths</span><span class="p">)):</span>
    <span class="n">words</span><span class="p">,</span> <span class="n">distance</span> <span class="o">=</span> <span class="n">vq</span><span class="p">(</span><span class="n">des_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">voc</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="n">im_features</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c"># Perform Tf-Idf vectorization</span>
<span class="n">nbr_occurences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">im_features</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mf">1.0</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">image_paths</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="n">nbr_occurences</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span> <span class="s">'float32'</span><span class="p">)</span>

<span class="c"># Perform L2 normalization</span>
<span class="n">im_features</span> <span class="o">=</span> <span class="n">im_features</span><span class="o">*</span><span class="n">idf</span>
<span class="n">im_features</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">im_features</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s">'l2'</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">im_features</span><span class="p">,</span> <span class="n">image_paths</span><span class="p">,</span> <span class="n">idf</span><span class="p">,</span> <span class="n">numWords</span><span class="p">,</span> <span class="n">voc</span><span class="p">),</span> <span class="s">"bof.pkl"</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre>
</div>
<p>将上面的文件保存为<code class="highlighter-rouge">findFeatures.py</code>，前面主要是一些通过parse使得可以在敲命令行的时候可以向里面传递参数，后面就是提取SIFT特征，然后聚类，计算TF和IDF，得到单词直方图后再做一下L2归一化。一般在一幅图像中提取的到SIFT特征点是非常多的，而如果图像库很大的话，SIFT特征点会非常非常的多，直接聚类是非常困难的(内存不够，计算速度非常慢)，所以，为了解决这个问题，可以以牺牲检索精度为代价，在聚类的时候先对SIFT做降采样处理。最后对一些在在线查询时会用到的变量保存下来。对于某个图像库，可以在命令行里通过下面命令生成BoF：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python findFeatures.py -t dataset/train/
</code></pre>
</div>

<p>在线查询阶段相比于上面简单了些，没有了聚类过程，具体代码如下:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">#!/usr/local/bin/python2.7</span>
<span class="c">#python search.py -i dataset/train/ukbench00000.jpg</span>

<span class="kn">import</span> <span class="nn">argparse</span> <span class="kn">as</span> <span class="nn">ap</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">imutils</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.vq</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">rootsift</span> <span class="kn">import</span> <span class="n">RootSIFT</span>

<span class="c"># Get the path of the training set</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">ap</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-i"</span><span class="p">,</span> <span class="s">"--image"</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">"Path to query image"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="s">"True"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="c"># Get query image path</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">"image"</span><span class="p">]</span>

<span class="c"># Load the classifier, class names, scaler, number of clusters and vocabulary</span>
<span class="n">im_features</span><span class="p">,</span> <span class="n">image_paths</span><span class="p">,</span> <span class="n">idf</span><span class="p">,</span> <span class="n">numWords</span><span class="p">,</span> <span class="n">voc</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">"bof.pkl"</span><span class="p">)</span>

<span class="c"># Create feature extraction and keypoint detector objects</span>
<span class="n">fea_det</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FeatureDetector_create</span><span class="p">(</span><span class="s">"SIFT"</span><span class="p">)</span>
<span class="n">des_ext</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DescriptorExtractor_create</span><span class="p">(</span><span class="s">"SIFT"</span><span class="p">)</span>

<span class="c"># List where all the descriptors are stored</span>
<span class="n">des_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">im</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="n">kpts</span> <span class="o">=</span> <span class="n">fea_det</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="n">kpts</span><span class="p">,</span> <span class="n">des</span> <span class="o">=</span> <span class="n">des_ext</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">kpts</span><span class="p">)</span>

<span class="c"># rootsift</span>
<span class="c">#rs = RootSIFT()</span>
<span class="c">#des = rs.compute(kpts, des)</span>

<span class="n">des_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">image_path</span><span class="p">,</span> <span class="n">des</span><span class="p">))</span>

<span class="c"># Stack all the descriptors vertically in a numpy array</span>
<span class="n">descriptors</span> <span class="o">=</span> <span class="n">des_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="c">#</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">numWords</span><span class="p">),</span> <span class="s">"float32"</span><span class="p">)</span>
<span class="n">words</span><span class="p">,</span> <span class="n">distance</span> <span class="o">=</span> <span class="n">vq</span><span class="p">(</span><span class="n">descriptors</span><span class="p">,</span><span class="n">voc</span><span class="p">)</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="n">test_features</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">w</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c"># Perform Tf-Idf vectorization and L2 normalization</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">test_features</span><span class="o">*</span><span class="n">idf</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s">'l2'</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">im_features</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">rank_ID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">score</span><span class="p">)</span>

<span class="c"># Visualize the results</span>
<span class="n">figure</span><span class="p">()</span>
<span class="n">gray</span><span class="p">()</span>
<span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ID</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rank_ID</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">16</span><span class="p">]):</span>
	<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">image_paths</span><span class="p">[</span><span class="n">ID</span><span class="p">])</span>
	<span class="n">gray</span><span class="p">()</span>
	<span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span>
	<span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
	<span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>
</code></pre>
</div>
<p>将上面的代码保存为<code class="highlighter-rouge">search.py</code>,对某幅图像进行查询时，只需在命令行里输入：</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">#python search.py -i dataset/train/ukbench00000.jpg(查询图像的路径)</span>
</code></pre>
</div>
<p>上面的代码中，你可以看到rootSIFT注释掉了，你也可以去掉注释，采用rootSIFT，但这里实验中我发觉rootSIFT并没有SIFT的效果好。最后看看检索的效果，最上面一张是查询图像，后面的是搜索到的图像：</p>

<p><img src="/images/posts/2015-06-16/ukbench00000.jpg" alt="ukbench00000" /></p>

<p><img src="/images/posts/2015-06-16/ukbench00055.jpg" alt="ukbench00055" /></p>

<h2 id="c">词袋模型图像检索C++实战</h2>

<p><strong>整个实战的代码可以在这里下载：<a href="https://github.com/willard-yuan/image-retrieval/tree/master/BoF">下载地址</a></strong>。</p>

<p><strong>致谢</strong>：基础框架来源<a href="https://github.com/grapeot/BoW">BoW</a>，开发版本在此基础上进行，已在Ubuntu、OS X上测试通过，Windows需要支持c++11的编译器(VS2012及其以上)。</p>

<p><img src="http://i300.photobucket.com/albums/nn17/willard-yuan/blog/Screen%20Shot%202015-08-13%20at%209.15.33%20PM_zpsq8qvkew7.png" alt="" /></p>

<h3 id="section-1">使用</h3>

<p>代码下载地址：<a href="https://github.com/willard-yuan/image-retrieval/tree/master/bag-of-words-stable-version">bag-of-words-stable-version</a>，这个是稳定版，上层目录里的开发版不要下载，那是我添加测试新模块所用的。</p>

<h3 id="section-2">编译</h3>

<p>修改<code class="highlighter-rouge">Makefile</code>文件，如果你的系统支持多线程技术，将</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CFLAGS <span class="o">=</span> -std<span class="o">=</span>c++11
</code></pre>
</div>

<p>修改为</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CFLAGS <span class="o">=</span> -std<span class="o">=</span>c++11 -fopenMP <span class="c"># if openMP accesses, using this</span>
</code></pre>
</div>

<p>修改完上面后，再修改编译所需的OpenCV和cppsugar，即</p>

<div class="highlighter-rouge"><pre class="highlight"><code>INCPATH <span class="o">=</span> -I/usr/local/include -I/Users/willard/codes/cpp/opencv-computer-vision/cpp/BoVW/cppsugar
LIBPATH <span class="o">=</span> -L/usr/local/lib
</code></pre>
</div>

<p><code class="highlighter-rouge">/usr/local/include</code>和<code class="highlighter-rouge">/usr/local/lib</code>分别是OpenCV所在的包含头文件目录路径和库目录路径，修改为你本机所在的目录即可。后面的cppsugar目录同样换成你本机的目录。
修改。这些修改完成后，执行下面命令进行编译：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>make
</code></pre>
</div>

<p>编译后即可在所在目录生成可执行文件。</p>

<h3 id="section-3">生成图库列表文件</h3>

<p>对于待检索的图像库imagesDataSet，执行下面命令</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python imgNamesToTXT.py -t /Users/willard/Pictures/imagesDataSet
</code></pre>
</div>

<p>上面执行后生成一个<code class="highlighter-rouge">imageNamesList.txt</code>的文件，该文件中包含的是每幅图像的路径及其图像文件名。</p>

<h3 id="section-4">建立索引</h3>

<p>执行下面命令，会完成特征提取、生成词典、量化生成bag of word向量：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>./index imageNamesList.txt
</code></pre>
</div>

<p>上面命令执行玩，会生成两个文件<code class="highlighter-rouge">bows.dat</code>和<code class="highlighter-rouge">dict.dat</code>，分别存放的是图像库每幅图像的bag of word向量以及词典。</p>

<h3 id="section-5">查询图像</h3>

<p>按下面命令进行查询</p>

<div class="highlighter-rouge"><pre class="highlight"><code>./search /Users/willard/Pictures/first1000/ukbench00499.jpg imageNamesList.txt
</code></pre>
</div>

<p>其中<code class="highlighter-rouge">/Users/willard/Pictures/first1000/ukbench00499.jpg</code>是查询图像，执行完后，会生成一个<code class="highlighter-rouge">result.html</code>的文件，应为要显示检索结果，所以这里采用的是用html页面的方式显示检索结果的，用浏览器打开即可。</p>

<h3 id="section-6">批量测试</h3>

<p>为了评价检索的效果，可以使用<code class="highlighter-rouge">ukbenchScores.cpp</code>计算在ukbench图像库上的NS score(NS分数)，下面是在ukbench1000张图像上计算的NS score:</p>

<p><strong>Ukbench</strong> first 1000 images, the NS-scores: 3.358, with tf*idf and histogram intersection kernel distance.</p>

<p><strong>Ukbench</strong> first 1000 images, the NS-scores: 3.602, with tf and histogram intersection kernel distance.</p>

<p><strong>注意</strong>，该框架中采用的相似性度量方式是直方图相交(histogram intersection kernel)的方法，测试发现直方图相交的方法要比用余弦距离度量的方式效果更好，但计算速度较慢。</p>

<p>开发版本<a href="https://github.com/willard-yuan/image-retrieval/tree/master/bag-of-words-dev-version">bag-of-words-dev-version</a>中加入了逆文档词频以及RANSAC重排，待效果达到预期后，会添加到稳定版中。</p>

  	</div>
	</div>
</article>

<!--翻页功能-->
<section class="inner">
<ul class="pager">
    
    <li class="previous">
       <a href="/blog/vlfeat-slic-with-qt.html">←Qt之VLFeat SLIC超像素分割(Cpp版)</a>
    </li>
    
    
    <li class="next">
    	<a href="/blog/SIFT(ASIFT)-Matching-with-RANSAC.html">SIFT Matching with RANSAC→</a>
    </li>
    
 </ul>
</section>

<!--评论功能-->
<section class="comments inner duoshuo">
<!-- Duoshuo Comment BEGIN -->
<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"yuanyong"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0]
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
</script>
<!-- Duoshuo Comment END -->

<!-- Disqus Comment BEGIN -->
  <!--<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'yongyuan'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>-->
<!-- Disqus Comment END -->

</section>
</div>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>



  <!--<div class="separator"></div>-->

  <div  style="border-bottom: 1px solid #eee"></div>
    <footer>
    <p class="linkings">
        Friend: <a href="http://peqiu.com/">Xuguo</a>&nbsp&nbsp&nbsp&nbsp<a href="http://jasonmpe.github.io/">HaiTao</a>&nbsp&nbsp&nbsp&nbsp<a href="http://raphael-mou.github.io/">Lichao</a>&nbsp&nbsp&nbsp&nbsp<a href="http://haobo-lv.github.io/">Haobo</a>&nbsp&nbsp&nbsp&nbsp<a href="http://www.52ml.net/">52ml</a>&nbsp&nbsp&nbsp&nbsp<a href="http://caoyaqiang.com/">cyq</a>&nbsp&nbsp&nbsp&nbsp<a href="http://personal.ee.surrey.ac.uk/Personal/R.Hu/">Rui Hu</a>&nbsp&nbsp&nbsp&nbsp<a href="http://www.pyimagesearch.com/">pyimagesearch</a>&nbsp&nbsp&nbsp&nbsp<a href="http://bean.logdown.com/">bean</a>&nbsp&nbsp&nbsp&nbsp<a href="http://ml.memect.com/">ml dairy</a>&nbsp&nbsp&nbsp&nbsp<a href="http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html/">Resources</a>
    </p>
    <p class="linkings">
        Utils: <a href="http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html">rogerioferis</a>&nbsp&nbsp&nbsp&nbsp<a href="http://caffe.berkeleyvision.org/">Caffe</a>&nbsp&nbsp&nbsp&nbsp<a href="http://scikit-learn.org/stable/index.html">scikit-learn</a>&nbsp&nbsp&nbsp&nbsp<a href="http://www.astroml.org/index.html">AstroML</a></a>&nbsp&nbsp&nbsp&nbsp<a href="http://scikit-image.org/">scikit-image</a></a>&nbsp&nbsp&nbsp&nbsp<a href="http://gitxiv.com/">GitXiv</a>
    </p>
    <p>
      Made with <a href="http://jekyllrb.com/">Jekyll</a>,
      hosted on <a href="https://github.com/willard-yuan/willard-yuan.github.io">Github Pages</a>. Inspired by <a href="http://sebastien.saunier.me/">saunier</a>, designed by <a href="http://yongyuan.name">Willard</a>.
    </p>
    </p>
      <a href="http://www.easycounter.com/"><img src="http://www.easycounter.com/counter.php?willard"border="0" alt="Website Hit Counter"></a> since August 2013.
    </p>
    <ul class="links">
      <!--li>
        <a href="https://github.com/willard-yuan" title="See my code on GitHub">
          <i class="icon-github"></i>
        </a>
      </li>
      <li>
        <a href="https://twitter.com/intent/follow?screen_name=yongyuan001" title="Follow me on Twitter">
          <i class="icon-twitter"></i>
        </a>
      </li>
      <li>
        <a href="https://www.linkedin.com/in/sebastiensaunier" title="Connect with me on LinkedIn">
          <i class="icon-linkedin"></i>
        </a>
      </li>
      <li>
        <a href="https://plus.google.com/+SebastienSaunier?rel=author" title="I need this link for authorship reasons">
          <i class="icon-google-plus"></i>
        </a>
      </li>
      <li>
        <a href="https://pinboard.in/u:ssaunier" title="Browse my bookmarks about Programming">
          <i class="icon-bookmarks"></i>
        </a>
      </li>
      <li>
        <a href="/feed.xml" title="Subscribe to my blog with RSS">
          <i class="icon-feed"></i>
        </a>
      </li-->
    </ul>
  </footer>

<script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>

</body>
</html>
